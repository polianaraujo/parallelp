# Relat√≥rio 11 - Impacto das cl√°usulas schedule e collapse
Aluna: Poliana Ellen de Ara√∫jo


## 1. Introdu√ß√£o

Este relat√≥rio apresenta uma **simula√ß√£o da equa√ß√£o de Navier-Stokes** considerando apenas a viscosidade, sem press√£o ou for√ßas externas. A simula√ß√£o utiliza **diferen√ßas finitas** para discretizar o espa√ßo e acompanhar a evolu√ß√£o da velocidade do fluido ao longo do tempo.

Inicialmente, o fluido foi configurado em repouso ou com velocidade constante, seguido da introdu√ß√£o de uma pequena perturba√ß√£o para observar a estabilidade do campo.

Ap√≥s a valida√ß√£o, o c√≥digo foi **paralelizado com OpenMP**, avaliando o impacto das cl√°usulas `schedule` e `collapse` no desempenho.

Foram realizados dois conjuntos de experimentos:

* **Com perturba√ß√£o (vers√£o sequencial):** para an√°lise visual do comportamento da simula√ß√£o.
* **Sem perturba√ß√£o (vers√£o paralela):** para testes de desempenho, sem interfer√™ncia de valores iniciais n√£o-nulos.

A equa√ß√£o da viscosidade (sem press√£o e for√ßas externas) em duas dimens√µes √© dada por:

$$ \frac{ùúïu}{ùúït}=vùõª^{2}u $$

Onde:
- $u$: Campo de velocidade do fluido
- $v$: Coeficiente de viscosidade
- $ùõª^{2}$: Operador Laplaciano

![navier_stokes_diffusion](navier_stokes_diffusion.gif)


## 2. Metodologia

### 2.1. C√≥digo Sequencial - Equa√ß√£o considerando apenas a viscosidade
- Defini√ß√£o de Constantes:
    - `NX` e `NY`: Dimens√µes da grade, nesse caso `100x100`.
    - `NSTEPS`: N√∫mero de passos de tempo, nesse caso `1000`.
    - `DT`: Passo de tempo, nesse caso `0,1`.
    - `VISCOSITY`: Coeficiente de viscosidade, nesse caso `0,1`.
- Fun√ß√£o ``initialize_field``:
    - Inicializa o campo de velocidade com zeros.
    - Introduz uma perturba√ß√£o no centro da grade.
- Fun√ß√£o ``update_field``:
    - Calcula a pr√≥xima itera√ß√£o do campo (como ele se comporta com o tempo) usando a f√≥rmula discreta da equa√ß√£o de Navier-Stokes.
- Fun√ß√£o ``simulate``:
    - Realiza a simula√ß√£o iterativa, em `NSTEPS`.
    - Em cada itera√ß√£o, a fun√ß√£o update_field √© chamada para atualizar o campo (simula√ß√£o de como a velocidade do fluido, em cada ponto da malha, muda ao longo do tempo, considerando apenas os efeitos da difus√£o viscosa).
- Fun√ß√£o ``print_field``:
    - Imprime o campo em formato simplificado para monitoramento.
- Fun√ß√£o ``main``:
    - Inicializa o campo, executa a simula√ß√£o calculando o tempo atrav√©s da fun√ß√£o `gettimeofday()`.


### 2.2. C√≥digo Paralelo - Com OpenMP

A simula√ß√£o foi paralelizada com OpenMP para explorar m√∫ltiplos threads e melhorar o desempenho. As regi√µes paralelizadas foram:

* C√°lculo do laplaciano interno da matriz.
* C√≥pia da matriz `next` para `current` a cada passo de tempo.

O c√≥digo foi executado **com e sem perturba√ß√£o** (linha 21 comentada).

Foram testadas:

* Estrat√©gias de escalonamento: `static`, `dynamic` e `guided`.
* Tamanhos de chunk: 1, 4 e 8.
* N√∫meros de threads: 1, 2, 4, 8 e 16.

A inicializa√ß√£o foi feita com o campo zerado para garantir consist√™ncia. O tempo de execu√ß√£o foi medido com `omp_get_wtime()`.

**Modifica√ß√µes no c√≥digo:**

* Inclus√£o de `#include <omp.h>`.
* Na fun√ß√£o `update_field`, foi usada a diretiva:

  ```c
  #pragma omp parallel for collapse(2) schedule(static)
  ```

  * `parallel for`: paraleliza o loop.
  * `collapse(2)`: unifica os loops `i` e `j`.
  * `schedule(...)`: define a estrat√©gia de distribui√ß√£o (tamb√©m testadas `dynamic` e `guided`).

A fun√ß√£o `run_simulation` permite executar a simula√ß√£o variando:

* N√∫mero de threads.
* Tipo de escalonamento.
* Tamanho do chunk.

Essas varia√ß√µes foram usadas para analisar o impacto da paraleliza√ß√£o no desempenho.

### 2.3. Execu√ß√£o

```
gcc -o sequential sequential.c -lm
./sequential
gcc -o parallel parallel.c -fopenmp -lm
./parallel
```

## 3. Resultados

Enquanto os dados da execu√ß√£o sem perturba√ß√£o (transformando a linha acima comentada), foram salvos em um arquivo chamado results_sem_perturbacao.csv.

|Sem perturba√ß√£o|Com perturba√ß√£o|
|-----|-----|
|![combined_analysis_sem_perturb](https://github.com/polianaraujo/parallelp/blob/main/tarefa11/plots_sem_perturb/combined_analysis_sem_perturb.png)|![Combina√ß√£o](https://github.com/polianaraujo/parallelp/blob/main/tarefa11/plots_w_perturb/combined_analysis_w_perturb.png)|
|![Combina√ß√£o](https://github.com/polianaraujo/parallelp/blob/main/tarefa11/plots_sem_perturb/time_per_chunk_sem_perturb.png)|![Combina√ß√£o](https://github.com/polianaraujo/parallelp/blob/main/tarefa11/plots_w_perturb/time_per_chunk_w_perturb.png)|

### üîπ 3.1. Sem perturba√ß√£o

- O escalonamento guided apresentou o melhor desempenho geral, principalmente com 2, 4 e 8 threads.

- O dynamic mostrou maior variabilidade e, em alguns casos, pior desempenho.

- Com 16 threads, todos os agendamentos apresentaram piora no tempo de execu√ß√£o, indicando excesso de paralelismo.

- O tempo de execu√ß√£o diminui com o aumento de threads at√© 8, sendo esse o ponto √≥timo.

- Chunk size menor (1) gera maior tempo, devido ao overhead de agendamento.

- Chunk sizes 4 e 8 s√£o mais eficientes, especialmente com escalonamento guided.

- No modo static, a varia√ß√£o com o chunk size √© pequena.

### üîπ 3.2. Com perturba√ß√£o

- O comportamento geral se mant√©m semelhante ao caso sem perturba√ß√£o, com o guided se destacando em efici√™ncia.

- O uso de 16 threads continua sendo ineficiente por conta da sobrecarga.

- O chunk size 1 √© mais afetado por perturba√ß√µes, resultando em maior tempo de execu√ß√£o.

- Chunk sizes 4 e 8 seguem mais robustos, principalmente no escalonamento static.

## 4. Conclus√µes

* O escalonamento `guided` teve o melhor desempenho, especialmente com at√© 4 threads.
* `Dynamic` mostrou baixa efici√™ncia em cen√°rios com muitas threads, sendo pouco indicado para escalabilidade fraca.
* O melhor desempenho geral foi com at√© 4 threads; acima disso, o overhead compromete os ganhos.
* A cl√°usula `collapse=1` foi, em geral, mais eficiente com muitas threads.
* O paralelismo deve ser ajustado ao tamanho da carga: muitos threads em problemas pequenos reduzem a efici√™ncia.
* A escolha ideal combina pol√≠tica de escalonamento, n√∫mero de threads e uso de `collapse`, sendo `static` ou `guided` mais indicados para cargas maiores.
