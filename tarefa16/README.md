# Relat√≥rio 16 - Comunica√ß√£o Coletiva com MPI
Aluna: Poliana Ellen de Ara√∫jo

## 1. Introdu√ß√£o


## 2. Metodologia



## 3. Resultados




![Compara√ß√£o das afinidades de todas as threads](https://github.com/polianaraujo/parallelp/blob/main/tarefa16/tempo_vs_processos_tamanhos_matrizes.png)

## 4. Conclus√µes

- üìà Tend√™ncias observadas
    - ‚úÖ Efici√™ncia do paralelismo:
        - A paraleliza√ß√£o melhora o desempenho at√© certo ponto.
        - O n√∫mero √≥timo de processos varia com o tamanho do problema (M e N).

- ‚ùå Overhead de comunica√ß√£o:
    - Quando M ou N s√£o pequenos, muitos processos introduzem mais overhead do que benef√≠cio.
    - Quando M √© grande o suficiente, o paralelismo compensa o overhead ‚Äî mas at√© um certo ponto.


- Problemas pequenos (ex: M=1000, N=100): poucos processos j√° s√£o suficientes; muitos processos n√£o trazem ganho significativo.

- Problemas m√©dios (ex: M=10000, N=1000): 4 a 8 processos s√£o eficazes, mas deve-se monitorar a sobrecarga.

- Problemas grandes (ex: M=50000, N=1000): 4 processos parecem ser o ponto de equil√≠brio; 8 processos aumentam a comunica√ß√£o e n√£o compensam em desempenho.